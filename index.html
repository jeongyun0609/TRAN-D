<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="">
  <meta name="keywords" content="Sparse view, transparent, depth reconstruction">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>2D Gaussian Splatting-based Sparse-view Transparent Object
    Depth Reconstruction via Physics Simulation for Scene Update</title>


  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script type="module" src="https://ajax.googleapis.com/ajax/libs/model-viewer/4.0.0/model-viewer.min.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-YXDZHQRVSJ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-YXDZHQRVSJ');
</script>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h2 class="title is-2 publication-title">2D Gaussian Splatting-based Sparse-view Transparent Object<br>
            Depth Reconstruction via Physics Simulation for Scene Update</h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://jeongyun0609.github.io/" target="_blank">Jeongyun Kim<sup>1</sup></a>,</span>
            <span class="author-block">
              <a >Seunghoon Jeong<sup>1</sup></a>,</span>
            <span class="author-block">
              <a href="https://gisbi-kim.github.io/" target="_blank">Giseop Kim<sup>2</sup></a>,</span>
            <span class="author-block">
              <a href="https://myunghwanjeon.github.io/" target="_blank">Myung-Hwan Jeon<sup>3</sup></a>,</span>
            <span class="author-block">
              <a >Eunji Jun<sup>4</sup></a>,</span>
            <span class="author-block">
              <a href="https://ayoungk.github.io/" target="_blank">Ayoung Kim<sup>1</sup></a></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Seoul National University, <sup>2</sup>DGIST, <sup>3</sup>University of Illinois Urbana-Champaign, <sup>4</sup> Hyundai Motor Group</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">ICCV 2025</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2507.11069"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/jeongyun0609/TRAN-D"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Understanding the 3D geometry of transparent objects from RGB images is challenging due to their inherent physical properties, such as reflection and refraction. To address these difficulties, especially in scenarios with sparse views and dynamic environments, we introduce TRAN-D, a novel 2D Gaussian Splatting-based depth reconstruction method for transparent objects.
            Our key insight lies in separating transparent objects from the background, enabling focused optimization of Gaussians corresponding to the object. We mitigate artifacts with an object-aware loss that places Gaussians in obscured regions, ensuring coverage of invisible surfaces while reducing overfitting. Furthermore, we incorporate a physics-based simulation that refines the reconstruction in just a few seconds, effectively handling object removal and chain-reaction movement of remaining objects without the need for rescanning.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method Overview</h2>
        <div class="content has-text-justified">
          <p>
            TRAN-D is a three-stage framework for reconstructing transparent objects from sparse RGB views. 
            First, the <em>segmentation module</em> isolates transparent object instances using Grounded SAM, trained with a category-specific prompting strategy. 
            Next, 2D Gaussians are randomly initialized and optimized in the <em>object-aware 2D Gaussian Splatting module</em> using differentiable tile rasterization and a novel object-aware 3D loss. 
            This step produces dense and artifact-free object reconstructions. 
            Finally, the <em>scene update module</em> employs physics-based simulation to refine the reconstruction after object removal, handling chain-reaction movements without requiring re-scanning.
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="./images/figure2.png" alt="Method figure."/>
        </div>
      </div>
    </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results</h2>
        <!-- Subsection. -->

        <h3 class="title is-4">Segmentation results</h3>
        <div class="content has-text-justified">
          <p>
            We fine-tuned Grounded SAM using only synthetic data generated from the TransPose dataset.Despite being trained exclusively on synthetic images, the model generalizes well to real-world scenarios, accurately segmenting transparent objects across diverse scenes.
          </p>
        </div>
        <div class="content has-text-centered">
            <img src="./images/seg_syn.png" alt="LEAP Comparison figure." width="100%"/>
        </div>

        <div class="content has-text-centered">
            <img src="./images/seg_real.png" alt="LEAP Comparison figure." width="100%"/>
        </div>


      <!-- Subsection. -->
        <h3 class="title is-4">Unknown Object Depth Reconstruction Results on Synthetic Sequences</h3>
        <div class="content has-text-justified">
          <p>
            Synthetic sequence depth reconstruction: Textureless
          </p>

      <!-- Flexbox container for 3 items in a row -->
      <div style="display: flex; justify-content: center; gap: 1.5rem; flex-wrap: wrap;">
        <!-- Item 1 -->
        <div style="text-align: center; width: 30%;">
          <img src="./images/textureless1_0.png" alt="Result 1" style="width: 100%;"/>
          <video style="width: 100%; margin-top: 0.5rem;" controls muted loop>
            <source src="./videos/textureless1_0.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Item 2 -->
        <div style="text-align: center; width: 30%;">
          <img src="./images/textureless2_0.png" alt="Result 2" style="width: 100%;"/>
          <video style="width: 100%; margin-top: 0.5rem;" controls muted loop>
            <source src="./videos/textureless2_0.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Item 3 -->
        <div style="text-align: center; width: 30%;">
          <img src="./images/textureless3_0.png" alt="Result 3" style="width: 100%;"/>
          <video style="width: 100%; margin-top: 0.5rem;" controls muted loop>
            <source src="./videos/textureless3_0.mp4" type="video/mp4">
          </video>
        </div>
      </div>

      <!-- Flexbox container for 3 items in a row -->
      <div style="display: flex; justify-content: center; gap: 1.5rem; flex-wrap: wrap;">
        <!-- Item 1 -->
        <div style="text-align: center; width: 30%;">
          <img src="./images/textureless1_1.png" alt="Result 1" style="width: 100%;"/>
          <video style="width: 100%; margin-top: 0.5rem;" controls muted loop>
            <source src="./videos/textureless1_1.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Item 2 -->
        <div style="text-align: center; width: 30%;">
          <img src="./images/textureless2_1.png" alt="Result 2" style="width: 100%;"/>
          <video style="width: 100%; margin-top: 0.5rem;" controls muted loop>
            <source src="./videos/textureless2_1.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Item 3 -->
        <div style="text-align: center; width: 30%;">
          <img src="./images/textureless3_1.png" alt="Result 3" style="width: 100%;"/>
          <video style="width: 100%; margin-top: 0.5rem;" controls muted loop>
            <source src="./videos/textureless3_1.mp4" type="video/mp4">
          </video>
        </div>
      </div>


        <div class="content has-text-justified"> 
          <p>Synthetic sequence depth reconstruction: Texture</p>
        </div>
      <!-- Flexbox container for 3 items in a row -->
      <div style="display: flex; justify-content: center; gap: 1.5rem; flex-wrap: wrap;">
        <!-- Item 1 -->
        <div style="text-align: center; width: 30%;">
          <img src="./images/texture1_0.png" alt="Result 1" style="width: 100%;"/>
          <video style="width: 100%; margin-top: 0.5rem;" controls muted loop>
            <source src="./videos/texture1_0.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Item 2 -->
        <div style="text-align: center; width: 30%;">
          <img src="./images/texture2_0.png" alt="Result 2" style="width: 100%;"/>
          <video style="width: 100%; margin-top: 0.5rem;" controls muted loop>
            <source src="./videos/texture2_0.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Item 3 -->
        <div style="text-align: center; width: 30%;">
          <img src="./images/texture3_0.png" alt="Result 3" style="width: 100%;"/>
          <video style="width: 100%; margin-top: 0.5rem;" controls muted loop>
            <source src="./videos/texture3_0.mp4" type="video/mp4">
          </video>
        </div>
      </div>

      <div style="display: flex; justify-content: center; gap: 1.5rem; flex-wrap: wrap;">
        <!-- Item 1 -->
        <div style="text-align: center; width: 30%;">
          <img src="./images/texture1_1.png" alt="Result 1" style="width: 100%;"/>
          <video style="width: 100%; margin-top: 0.5rem;" controls muted loop>
            <source src="./videos/texture1_1.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Item 2 -->
        <div style="text-align: center; width: 30%;">
          <img src="./images/texture2_1.png" alt="Result 2" style="width: 100%;"/>
          <video style="width: 100%; margin-top: 0.5rem;" controls muted loop>
            <source src="./videos/texture2_1.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Item 3 -->
        <div style="text-align: center; width: 30%;">
          <img src="./images/texture3_1.png" alt="Result 3" style="width: 100%;"/>
          <video style="width: 100%; margin-top: 0.5rem;" controls muted loop>
            <source src="./videos/texture3_1.mp4" type="video/mp4">
          </video>
        </div>
      </div>

        <!-- Subsection. -->
        <h3 class="title is-4">Unknown Object Segmentation and Depth Reconstruction Results on Real-World Mixed Sequences</h3>
        <div class="content has-text-justified">
          <p>

          </p>
        </div>
        <div class="content has-text-centered">
            <img src="./images/mix.png" alt="LEAP Comparison figure." width="100%"/>
        </div>

        <!-- Subsection.
        <div class="content has-text-centered">
            <img src="./research/DiffusionSfM/figures/vis_cameras.png" alt="LEAP Comparison figure." width="100%"/>
        </div> -->
      </div>
    </div>
  </div>
</section>




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3">BibTeX</h2>
<pre><code>@inproceedings{jeongyun2025TRAN-D,
  title={2D Gaussian Splatting-based Sparse-view Transparent Object Depth Reconstruction via Physics Simulation for Scene Update}, 
  author={Jeongyun Kim, Seunghoon Jeong, Giseop Kim, Myung-Hwan Jeon, Eunji Jun and Ayoung Kim},
  booktitle={ICCV},
  year={2025} 
}</code></pre>
  </div>
</section>


<section class="column" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title is-3">Acknowledgements</h2>
    <p>
      This work was supported by the National Research Founda- tion of Korea (NRF) grant funded by the Korea government (MSIT)(No. RS-2024-00461409), and in part by Hyundai Motor Company and Kia. and the Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea government(MSIT) No.2022-0- 00480, Development of Training and Inference Methods for Goal-Oriented Artificial Intelligence Agents.
    </p>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/abs/2507.11069">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/jeongyun0609/TRAN-D class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is built using this template (<a href="https://qitaozhao.github.io/DiffusionSfM">source code</a>).
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
